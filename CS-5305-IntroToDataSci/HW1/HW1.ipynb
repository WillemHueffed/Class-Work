{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requisite Libraries\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#nltk.download(\"punkt\") #this only needs to be run once per system\n",
    "import spacy #also run: \"python -m spacy download en_core_web_sm\" in terminal\n",
    "from spellchecker import SpellChecker\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: It is an important skill to look at the data and come up with questions that you can\n",
    "answer. What are some compelling questions that you can ask with the provided dataset (list at\n",
    "least 2 questions)? (5 points)\n",
    "\n",
    "1. What is the distribution of sentiments within the tweets?\n",
    "2. Is there a correlation between sentiment and tweet engagement (retweet or favorite)?\n",
    "3. What are the most frequent topics mentioned in the tweets?\n",
    "4. Who were the most frequently mentioned people or hashtags within the tweets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Inspect & Data Cleaning  \n",
    "● Inspect: Write code to inspect the data. What do you observe? Along with the code,\n",
    "write your observation in the markdown cell. (2.5 points)  \n",
    "● Clean: Write code to clean the data. Use at least 5 methods. For each method, along\n",
    "with the code, you need to write the rationale behind the cleaning process. For this\n",
    "question, you can assume that you are solving one of the questions that you wrote for\n",
    "the first question. (5 points)  \n",
    "● Tokenize: Write code to tokenize your entire dataset. Use at least 2 different types of\n",
    "tokenizers. Compare their results and write your observations. (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               source                                               text  \\\n",
      "0  Twitter for iPhone  RT @ScottAdamsSays: Malaria drug and zinc the ...   \n",
      "1  Twitter for iPhone  RT @YoungDems4Trump: In Democrat cities you ca...   \n",
      "2  Twitter for iPhone  RT @YoungDems4Trump: So sad. This poor busines...   \n",
      "3  Twitter for iPhone   Time for a change! #2020 https://t.co/AECy2GBfys   \n",
      "4  Twitter for iPhone  RT @TallahForTrump: Trump spoke at my church i...   \n",
      "\n",
      "            created_at  retweet_count  favorite_count is_retweet  \\\n",
      "0  05-30-2020 03:26:31          10566               0       True   \n",
      "1  05-30-2020 03:21:41          22320               0       True   \n",
      "2  05-30-2020 03:21:32          23961               0       True   \n",
      "3  05-30-2020 03:20:18          42879          164022      False   \n",
      "4  05-30-2020 03:19:01          36563               0       True   \n",
      "\n",
      "                id_str  \n",
      "0  1266571665204527109  \n",
      "1  1266570449431003138  \n",
      "2  1266570411678019584  \n",
      "3  1266570099454103553  \n",
      "4  1266569778770182151  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18467 entries, 0 to 18466\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   source          18467 non-null  object\n",
      " 1   text            18467 non-null  object\n",
      " 2   created_at      18467 non-null  object\n",
      " 3   retweet_count   18467 non-null  int64 \n",
      " 4   favorite_count  18467 non-null  int64 \n",
      " 5   is_retweet      18409 non-null  object\n",
      " 6   id_str          18467 non-null  int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 1010.0+ KB\n",
      "None\n",
      "(18467, 7)\n",
      "Index(['source', 'text', 'created_at', 'retweet_count', 'favorite_count',\n",
      "       'is_retweet', 'id_str'],\n",
      "      dtype='object')\n",
      "\n",
      "missing values count:\n",
      "source             0\n",
      "text               0\n",
      "created_at         0\n",
      "retweet_count      0\n",
      "favorite_count     0\n",
      "is_retweet        58\n",
      "id_str             0\n",
      "dtype: int64\n",
      "Duplicate count: 0\n",
      "Source contains homogenous values: False\n",
      "The unique values for source are: ['Twitter for iPhone' 'Twitter Media Studio' 'Twitter Web App'\n",
      " 'Twitter Web Client' 'Twitter for iPad' 'Media Studio' 'Twitter Ads'\n",
      " 'Twitter for Android']\n"
     ]
    }
   ],
   "source": [
    "#Read in data and inspect\n",
    "tweet_df = pd.read_csv(\"trump_20200530.csv\")\n",
    "print(tweet_df.head())\n",
    "print(tweet_df.info())\n",
    "print(tweet_df.shape)\n",
    "print(tweet_df.columns)\n",
    "print(\"\\nmissing values count:\\n{}\".format(tweet_df.isna().sum()))\n",
    "print(\"Duplicate count: {}\".format(tweet_df.duplicated().sum()))\n",
    "print(\"Source contains homogenous values: {}\".format((tweet_df[\"source\"] == tweet_df[\"source\"].iloc[0]).all()))\n",
    "print(\"The unique values for source are: {}\".format(tweet_df[\"source\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source            0\n",
      "text              0\n",
      "created_at        0\n",
      "retweet_count     0\n",
      "favorite_count    0\n",
      "is_retweet        0\n",
      "id_str            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Clean data\n",
    "#Assuming we're trying to find the distribution of sentiments within the tweets\n",
    "\n",
    "#There are 58 rows with missing values out of 18446 total rows. We can drop these rows with negligable impact.\n",
    "tweet_df.dropna(inplace=True)\n",
    "print(tweet_df.isna().sum())\n",
    "\n",
    "#homogenize text by converting text to lower case, this should increase model accuracy\n",
    "tweet_df[\"text\"].str.lower()\n",
    "\n",
    "#remove stopwords, this reduces noise and dimensionality yielding better performance\n",
    "def cleanStopWords(text):\n",
    "    words = text.split() \n",
    "    filtered_words = [word for word in words if word not in stopwords.words('english')]\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "    return cleaned_text\n",
    "    \n",
    "tweet_df[\"text\"] = tweet_df[\"text\"].apply(cleanStopWords)\n",
    "\n",
    "#extract date from time produced field to make it usable for plotting\n",
    "tweet_df[\"date\"] = tweet_df[\"created_at\"].dt.date\n",
    "tweet_df.drop(\"created_at\")\n",
    "\n",
    "#drop non-relevant column, we don't need it - less memory consumed - better performance\n",
    "tweet_df.drop(column=\"source\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\willm\\OneDrive\\Desktop\\Class-Work\\CS-5305-IntroToDataSci\\HW1\\HW1.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willm/OneDrive/Desktop/Class-Work/CS-5305-IntroToDataSci/HW1/HW1.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     tokens \u001b[39m=\u001b[39m [token\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m document]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willm/OneDrive/Desktop/Class-Work/CS-5305-IntroToDataSci/HW1/HW1.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tokens\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/willm/OneDrive/Desktop/Class-Work/CS-5305-IntroToDataSci/HW1/HW1.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m tweet_df[\u001b[39m\"\u001b[39m\u001b[39mspacy_tokens\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m tweet_df[\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(spacy_tokenize)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\pandas\\core\\series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4753\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4754\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   4755\u001b[0m         func,\n\u001b[0;32m   4756\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[0;32m   4757\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[0;32m   4758\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   4759\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m-> 4760\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[0;32m   1288\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[0;32m   1289\u001b[0m )\n\u001b[0;32m   1291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\willm\\OneDrive\\Desktop\\Class-Work\\CS-5305-IntroToDataSci\\HW1\\HW1.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willm/OneDrive/Desktop/Class-Work/CS-5305-IntroToDataSci/HW1/HW1.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspacy_tokenize\u001b[39m(text):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/willm/OneDrive/Desktop/Class-Work/CS-5305-IntroToDataSci/HW1/HW1.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     tokenizer \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39men_core_web_sm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willm/OneDrive/Desktop/Class-Work/CS-5305-IntroToDataSci/HW1/HW1.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     document \u001b[39m=\u001b[39m tokenizer(text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willm/OneDrive/Desktop/Class-Work/CS-5305-IntroToDataSci/HW1/HW1.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     tokens \u001b[39m=\u001b[39m [token\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m document]\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     52\u001b[0m         name,\n\u001b[0;32m     53\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m     54\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m     55\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m     56\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m     57\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     58\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\spacy\\util.py:465\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[39mreturn\u001b[39;00m get_lang_class(name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mblank:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))()\n\u001b[0;32m    464\u001b[0m \u001b[39mif\u001b[39;00m is_package(name):  \u001b[39m# installed as package\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\spacy\\util.py:501\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[39mname (str): The package name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[39mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[1;32m--> 501\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mload(vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, enable\u001b[39m=\u001b[39;49menable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\en_core_web_sm\\__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides):\n\u001b[1;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_init_py(\u001b[39m__file__\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moverrides)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\spacy\\util.py:682\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_path\u001b[39m.\u001b[39mexists():\n\u001b[0;32m    681\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE052\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdata_path))\n\u001b[1;32m--> 682\u001b[0m \u001b[39mreturn\u001b[39;00m load_model_from_path(\n\u001b[0;32m    683\u001b[0m     data_path,\n\u001b[0;32m    684\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m    685\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[0;32m    686\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m    687\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m    688\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    689\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    690\u001b[0m )\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\spacy\\util.py:539\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    537\u001b[0m overrides \u001b[39m=\u001b[39m dict_to_dot(config, for_overrides\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    538\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[1;32m--> 539\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[0;32m    540\u001b[0m     config,\n\u001b[0;32m    541\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m    542\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m    543\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m    544\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    545\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[0;32m    546\u001b[0m )\n\u001b[0;32m    547\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39mfrom_disk(model_path, exclude\u001b[39m=\u001b[39mexclude, overrides\u001b[39m=\u001b[39moverrides)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\spacy\\util.py:587\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[1;34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[39m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[0;32m    585\u001b[0m \u001b[39m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[0;32m    586\u001b[0m lang_cls \u001b[39m=\u001b[39m get_lang_class(nlp_config[\u001b[39m\"\u001b[39m\u001b[39mlang\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m--> 587\u001b[0m nlp \u001b[39m=\u001b[39m lang_cls\u001b[39m.\u001b[39;49mfrom_config(\n\u001b[0;32m    588\u001b[0m     config,\n\u001b[0;32m    589\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m    590\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m    591\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m    592\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    593\u001b[0m     auto_fill\u001b[39m=\u001b[39;49mauto_fill,\n\u001b[0;32m    594\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    595\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[0;32m    596\u001b[0m )\n\u001b[0;32m    597\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\spacy\\language.py:1864\u001b[0m, in \u001b[0;36mLanguage.from_config\u001b[1;34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     factory \u001b[39m=\u001b[39m pipe_cfg\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfactory\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1862\u001b[0m     \u001b[39m# The pipe name (key in the config) here is the unique name\u001b[39;00m\n\u001b[0;32m   1863\u001b[0m     \u001b[39m# of the component, not necessarily the factory\u001b[39;00m\n\u001b[1;32m-> 1864\u001b[0m     nlp\u001b[39m.\u001b[39;49madd_pipe(\n\u001b[0;32m   1865\u001b[0m         factory,\n\u001b[0;32m   1866\u001b[0m         name\u001b[39m=\u001b[39;49mpipe_name,\n\u001b[0;32m   1867\u001b[0m         config\u001b[39m=\u001b[39;49mpipe_cfg,\n\u001b[0;32m   1868\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m   1869\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[0;32m   1870\u001b[0m     )\n\u001b[0;32m   1871\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1872\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m pipe_cfg\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\spacy\\language.py:821\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    817\u001b[0m     pipe_component, factory_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_pipe_from_source(\n\u001b[0;32m    818\u001b[0m         factory_name, source, name\u001b[39m=\u001b[39mname\n\u001b[0;32m    819\u001b[0m     )\n\u001b[0;32m    820\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 821\u001b[0m     pipe_component \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_pipe(\n\u001b[0;32m    822\u001b[0m         factory_name,\n\u001b[0;32m    823\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    824\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    825\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[0;32m    826\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    827\u001b[0m     )\n\u001b[0;32m    828\u001b[0m pipe_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[0;32m    829\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_meta[name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\spacy\\language.py:709\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[1;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    706\u001b[0m cfg \u001b[39m=\u001b[39m {factory_name: config}\n\u001b[0;32m    707\u001b[0m \u001b[39m# We're calling the internal _fill here to avoid constructing the\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39m# registered functions twice\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m resolved \u001b[39m=\u001b[39m registry\u001b[39m.\u001b[39;49mresolve(cfg, validate\u001b[39m=\u001b[39;49mvalidate)\n\u001b[0;32m    710\u001b[0m filled \u001b[39m=\u001b[39m registry\u001b[39m.\u001b[39mfill({\u001b[39m\"\u001b[39m\u001b[39mcfg\u001b[39m\u001b[39m\"\u001b[39m: cfg[factory_name]}, validate\u001b[39m=\u001b[39mvalidate)[\u001b[39m\"\u001b[39m\u001b[39mcfg\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    711\u001b[0m filled \u001b[39m=\u001b[39m Config(filled)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\confection\\__init__.py:756\u001b[0m, in \u001b[0;36mregistry.resolve\u001b[1;34m(cls, config, schema, overrides, validate)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    748\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresolve\u001b[39m(\n\u001b[0;32m    749\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    754\u001b[0m     validate: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    755\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m--> 756\u001b[0m     resolved, _ \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_make(\n\u001b[0;32m    757\u001b[0m         config, schema\u001b[39m=\u001b[39;49mschema, overrides\u001b[39m=\u001b[39;49moverrides, validate\u001b[39m=\u001b[39;49mvalidate, resolve\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    758\u001b[0m     )\n\u001b[0;32m    759\u001b[0m     \u001b[39mreturn\u001b[39;00m resolved\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\confection\\__init__.py:805\u001b[0m, in \u001b[0;36mregistry._make\u001b[1;34m(cls, config, schema, overrides, resolve, validate)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_interpolated:\n\u001b[0;32m    804\u001b[0m     config \u001b[39m=\u001b[39m Config(orig_config)\u001b[39m.\u001b[39minterpolate()\n\u001b[1;32m--> 805\u001b[0m filled, _, resolved \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_fill(\n\u001b[0;32m    806\u001b[0m     config, schema, validate\u001b[39m=\u001b[39;49mvalidate, overrides\u001b[39m=\u001b[39;49moverrides, resolve\u001b[39m=\u001b[39;49mresolve\n\u001b[0;32m    807\u001b[0m )\n\u001b[0;32m    808\u001b[0m filled \u001b[39m=\u001b[39m Config(filled, section_order\u001b[39m=\u001b[39msection_order)\n\u001b[0;32m    809\u001b[0m \u001b[39m# Check that overrides didn't include invalid properties not in config\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\confection\\__init__.py:860\u001b[0m, in \u001b[0;36mregistry._fill\u001b[1;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[0;32m    858\u001b[0m     schema\u001b[39m.\u001b[39m__fields__[key] \u001b[39m=\u001b[39m copy_model_field(field, Any)\n\u001b[0;32m    859\u001b[0m promise_schema \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmake_promise_schema(value, resolve\u001b[39m=\u001b[39mresolve)\n\u001b[1;32m--> 860\u001b[0m filled[key], validation[v_key], final[key] \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_fill(\n\u001b[0;32m    861\u001b[0m     value,\n\u001b[0;32m    862\u001b[0m     promise_schema,\n\u001b[0;32m    863\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    864\u001b[0m     resolve\u001b[39m=\u001b[39;49mresolve,\n\u001b[0;32m    865\u001b[0m     parent\u001b[39m=\u001b[39;49mkey_parent,\n\u001b[0;32m    866\u001b[0m     overrides\u001b[39m=\u001b[39;49moverrides,\n\u001b[0;32m    867\u001b[0m )\n\u001b[0;32m    868\u001b[0m reg_name, func_name \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_constructor(final[key])\n\u001b[0;32m    869\u001b[0m args, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mparse_args(final[key])\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\confection\\__init__.py:859\u001b[0m, in \u001b[0;36mregistry._fill\u001b[1;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[0;32m    857\u001b[0m     field \u001b[39m=\u001b[39m schema\u001b[39m.\u001b[39m__fields__[key]\n\u001b[0;32m    858\u001b[0m     schema\u001b[39m.\u001b[39m__fields__[key] \u001b[39m=\u001b[39m copy_model_field(field, Any)\n\u001b[1;32m--> 859\u001b[0m promise_schema \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmake_promise_schema(value, resolve\u001b[39m=\u001b[39;49mresolve)\n\u001b[0;32m    860\u001b[0m filled[key], validation[v_key], final[key] \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_fill(\n\u001b[0;32m    861\u001b[0m     value,\n\u001b[0;32m    862\u001b[0m     promise_schema,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    866\u001b[0m     overrides\u001b[39m=\u001b[39moverrides,\n\u001b[0;32m    867\u001b[0m )\n\u001b[0;32m    868\u001b[0m reg_name, func_name \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_constructor(final[key])\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\confection\\__init__.py:1068\u001b[0m, in \u001b[0;36mregistry.make_promise_schema\u001b[1;34m(cls, obj, resolve)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         sig_args[name] \u001b[39m=\u001b[39m (annotation, default)\n\u001b[0;32m   1067\u001b[0m sig_args[\u001b[39m\"\u001b[39m\u001b[39m__config__\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _PromiseSchemaConfig\n\u001b[1;32m-> 1068\u001b[0m \u001b[39mreturn\u001b[39;00m create_model(\u001b[39m\"\u001b[39;49m\u001b[39mArgModel\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msig_args)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\pydantic\\v1\\main.py:1026\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(__model_name, __config__, __base__, __module__, __validators__, __cls_kwargs__, __slots__, **field_definitions)\u001b[0m\n\u001b[0;32m   1024\u001b[0m     ns[\u001b[39m'\u001b[39m\u001b[39m__orig_bases__\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m __base__\n\u001b[0;32m   1025\u001b[0m namespace\u001b[39m.\u001b[39mupdate(ns)\n\u001b[1;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m meta(__model_name, resolved_bases, namespace, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\pydantic\\v1\\main.py:151\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[1;34m(mcs, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         hash_func \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39m\u001b[39m__hash__\u001b[39m\n\u001b[0;32m    147\u001b[0m resolve_forward_refs \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39m__resolve_forward_refs__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    148\u001b[0m allowed_config_kwargs: SetStr \u001b[39m=\u001b[39m {\n\u001b[0;32m    149\u001b[0m     key\n\u001b[0;32m    150\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(config)\n\u001b[1;32m--> 151\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (key\u001b[39m.\u001b[39;49mstartswith(\u001b[39m'\u001b[39;49m\u001b[39m__\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m__\u001b[39m\u001b[39m'\u001b[39m))  \u001b[39m# skip dunder methods and attributes\u001b[39;00m\n\u001b[0;32m    152\u001b[0m }\n\u001b[0;32m    153\u001b[0m config_kwargs \u001b[39m=\u001b[39m {key: kwargs\u001b[39m.\u001b[39mpop(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mkeys() \u001b[39m&\u001b[39m allowed_config_kwargs}\n\u001b[0;32m    154\u001b[0m config_from_namespace \u001b[39m=\u001b[39m namespace\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mConfig\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Tokenize text\n",
    "def spacy_tokenize(text):\n",
    "    tokenizer = spacy.load(\"en_core_web_sm\")\n",
    "    document = tokenizer(text)\n",
    "    tokens = [token.text for token in document]\n",
    "    return tokens\n",
    "    \n",
    "tweet_df[\"spacy_tokens\"] = tweet_df[\"text\"].apply(spacy_tokenize)\n",
    "\n",
    "def nltk_tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n",
    "    \n",
    "tweet_df[\"nltk_tokens\"] = tweet_df[\"text\"].apply(nltk_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Learn how to use new Python packages or online APIs (10 points)\n",
    "Pick an existing package a library or an API to determine the sentiment (positive, negative,\n",
    "neutral) for each of the tweets in the dataset. You can also use open-source code provided on\n",
    "GitHub repos. DO NOT WRITE THE SENTIMENT ANALYSIS CODE FROM SCRATCH\n",
    "For example: Use VADER sentiment analysis from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment(tokens):\n",
    "    text = \" \".join(tokens)\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    return sentiment[\"compound\"]\n",
    "\n",
    "tweet_df[\"sentiment_score\"] = df[\"tokens\"].apply(analyze_sentiment)\n",
    "\n",
    "def classify_sentiment_score(score):\n",
    "    if score >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"negative\"\n",
    "    else\n",
    "        return \"neutral\"\n",
    "\n",
    "tweet_df[\"sentiment_label\"] = tweet_df[\"sentiment_score\"].apply(classify_sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Analyze Data over time (10 points)\n",
    "How does the sentiment of your corpus change over time? Answer this question by showing\n",
    "plots (at least 2 graphs). Be creative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_by_day = tweet_df.groupby[tweet_df[\"date\"].dt.date[\"sentiment_score\"].mean()]\n",
    "\n",
    "plt.plot(daily_sentiment.index, daily_sentiment.values, label='Sentiment Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.title('Sentiment Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "negative_tweets = tweet_df[tweet_df[\"sentiment_label\"] == \"negative\"]\n",
    "negative_tweets_count = negative_tweets.groupby('date').size().reset_index(name='count')\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(negative_tweets_count['date'], negative_tweets_count['count'], marker='o', linestyle='-')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Negative Tweets')\n",
    "plt.title('Number of Negative Tweets Over Time')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "negative_tweets = tweet_df[tweet_df[\"sentiment_label\"] == \"positive\"]\n",
    "negative_tweets_count = negative_tweets.groupby('date').size().reset_index(name='count')\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(negative_tweets_count['date'], negative_tweets_count['count'], marker='o', linestyle='-')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Positive Tweets')\n",
    "plt.title('Number of Positive Tweets Over Time')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
